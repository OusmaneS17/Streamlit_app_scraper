import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import plotly.express as px
import time
from PIL import Image

# Configuration gÃ©nÃ©rale de la page
st.set_page_config(
    page_title="Web Scraper App ğŸš€",
    page_icon="ğŸ•¸ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Chargement des images
scraping_img = "https://images.unsplash.com/photo-1600703508486-75e63378fc8a"
dashboard_img = "data/barometer-6550830_1280.jpg"
evaluation_img = "https://cdn.pixabay.com/photo/2022/03/01/11/09/check-7044608_1280.jpg"

st.markdown("""
    <style>
        /* Personnalisation du menu latÃ©ral (sidebar) */
        .css-1d391kg {
            background-color: #4C6B89; /* Couleur de fond */
            border-radius: 10px;
            padding: 10px;
            font-family: 'Arial', sans-serif;
        }
        
        /* Personnalisation du texte du menu */
        .css-1d391kg label {
            font-size: 1.2rem;
            color: white;
            font-weight: bold;
        }

        /* Personnalisation des Ã©lÃ©ments du menu */
        .css-1d391kg .st-radio input {
            accent-color: #FFC107; /* Couleur du bouton sÃ©lectionnÃ© */
        }

        .css-1d391kg .st-radio label {
            font-size: 1.1rem;
            color: #D6E4F0;
        }

        /* Effet hover sur les Ã©lÃ©ments du menu */
        .css-1d391kg .st-radio label:hover {
            color: #FFC107;
            cursor: pointer;
        }

        /* Personnalisation de l'Ã©lÃ©ment actif */
        .css-1d391kg .st-radio label[aria-checked="true"] {
            color: white;
            font-weight: bold;
        }
            
        .metric-box {
            background-color: #f0f0f5;
            border-radius: 10px;
            padding: 20px;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .metric-box h3 {
            font-size: 1.5rem;
            font-weight: bold;
        }
        .metric-box p {
            font-size: 2rem;
            color: #333;
        }
        .stMetrics {
            display: flex;
            justify-content: space-between;
        }
    </style>
""", unsafe_allow_html=True)

# Barre latÃ©rale avec images et liens
st.sidebar.image(scraping_img, caption="ğŸš€ Bienvenue dans l'app !")
st.sidebar.title("ğŸ“Š Web Scraper Dashboard")
st.sidebar.markdown("Naviguez entre les sections ğŸ‘‡")

# Menu de navigation
menu = st.sidebar.radio("Choisissez une section :", ["ğŸ  Accueil", "ğŸ•µï¸â€â™‚ï¸ Scraping", "ğŸ“Š Dashboard", "ğŸ“ Ã‰valuation", "ğŸ“¥ Charger des DonnÃ©es ScrapÃ©es"])

# --- Page d'accueil ---
if menu == "ğŸ  Accueil":
    st.title("Bienvenue dans l'application Web Scraper ğŸ‰")
    st.image(scraping_img, use_column_width=True)
    st.markdown("""
    Cette application vous permet de :
    - **ğŸ” Scraper des donnÃ©es**
    - **ğŸ“Š Visualiser et analyser ces donnÃ©es**
    - **ğŸ’¾ TÃ©lÃ©charger les rÃ©sultats**
    - **ğŸ“ Ã‰valuer l'application avec un formulaire convivial**
    """)

    # Animation de chargement
    with st.spinner("Chargement des sections interactives..."):
        time.sleep(2)
    st.success("Les fonctionnalitÃ©s sont prÃªtes ! ğŸš€")

# --- Scraping ---
# Configuration du menu
if menu == "ğŸ•µï¸â€â™‚ï¸ Scraping":
    st.header("Scraping de DonnÃ©es ğŸ•µï¸")
    st.image(scraping_img, caption="Extraction intelligente de donnÃ©es", use_column_width=True)

    # URL et nombre de pages Ã  scraper pour Expat Dakar
    base_url = "https://www.expat-dakar.com/refrigerateurs-congelateurs?page="
    start_page = st.number_input("NumÃ©ro de page de dÃ©part :", min_value=1, value=2)
    end_page = st.number_input("NumÃ©ro de la derniÃ¨re page :", min_value=start_page, value=6)

    # Fonction de scraping Expat Dakar
    def scrape_data_expat_dakar(start_page, end_page):
        data_all_url1 = []
        for page_num in range(start_page, end_page + 1):
            url1 = base_url + str(page_num)
            try:
                response = requests.get(url1)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, "lxml")
                    data_table = soup.find('div', class_="listings-cards__list")

                    if data_table:
                        body_data_table = data_table.find_all('div', class_="listings-cards__list-item")

                        for listing_item in body_data_table:
                            # Extraction des dÃ©tails
                            titre_element = listing_item.find('div', class_='listing-card__header__title')
                            titre = titre_element.text.strip() if titre_element else "N/A"

                            etat_frigo_element = listing_item.find('div', class_='listing-card__header__tags')
                            etat_frigo = etat_frigo_element.text.strip() if etat_frigo_element else "N/A"

                            zone_element = listing_item.find('div', class_='listing-card__header__location')
                            zone = zone_element.text.strip() if zone_element else "N/A"

                            date_element = listing_item.find('div', class_='listing-card__header__date')
                            date = date_element.text.strip() if date_element else "N/A"

                            prix_element = listing_item.find('span', class_='listing-card__price__value')
                            prix = prix_element.text.strip() if prix_element else "N/A"

                            # Construction des donnÃ©es
                            row_data = {
                                "Titre": titre,
                                "Etat": etat_frigo,
                                "Adresse": zone,
                                "Prix": prix,
                                "Date Publication": date,
                                "URL Page": url1
                            }
                            data_all_url1.append(row_data)
                    else:
                        st.warning(f"âš ï¸ Aucune donnÃ©e trouvÃ©e pour la page {page_num}.")
                else:
                    st.error(f"Erreur pour la page {page_num}. Code : {response.status_code}")
            except Exception as e:
                st.error(f"Erreur lors du scraping de la page {page_num} : {e}")
        return pd.DataFrame(data_all_url1)

    # Bouton pour lancer le scraping
    if st.button("ğŸš€ Lancer le scraping"):
        with st.spinner("Scraping en cours..."):
            scraped_data = scrape_data_expat_dakar(start_page, end_page)
            if not scraped_data.empty:
                st.success(f"âœ… {len(scraped_data)} annonces rÃ©cupÃ©rÃ©es.")
                st.dataframe(scraped_data)

                # TÃ©lÃ©chargement des donnÃ©es en CSV
                csv = scraped_data.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger les donnÃ©es en CSV",
                    data=csv,
                    file_name="scraped_data.csv",
                    mime="text/csv"
                )
            else:
                st.warning("âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e.")

# --- Dashboard ---

# Charger les donnÃ©es
data = pd.read_excel("data/Cleaned/Climatisation_cleaned.xlsx")

if menu == "ğŸ“Š Dashboard":
    st.header("Dashboard des DonnÃ©es des climatiseursğŸ“Š")
    st.image(dashboard_img, caption="Analyse dynamique des donnÃ©es", use_column_width=True)

    if not data.empty:

        # ğŸ“Š BoÃ®tes pour afficher les KPIs
        col1, col2 = st.columns(2)

        # Prix moyen
        prix_moyen = data["Prix"].mean() if "Prix" in data.columns else 0
        with col1:
            st.markdown(f'<div class="metric-box"><h3>Prix Moyen (FCFA)</h3><p>{prix_moyen:,.0f}</p></div>', unsafe_allow_html=True)

        # Nombre d'annonces
        nombre_annonces = data.shape[0]
        with col2:
            st.markdown(f'<div class="metric-box"><h3>Nombre d\'Annonces</h3><p>{nombre_annonces:,}</p></div>', unsafe_allow_html=True)


        # ğŸŒŸ Graphique 1 : Distribution des prix
        if "Prix" in data.columns:
            data["Prix"] = pd.to_numeric(data["Prix"], errors="coerce").fillna(0).astype(int)
            fig1 = px.histogram(data, x="Prix", title="Distribution des Prix des Climatiseurs", nbins=20)
            st.plotly_chart(fig1, use_container_width=True)

        # ğŸŒŸ Graphique 2 : Nombre d'annonces par zone gÃ©ographique
        if "Adresse" in data.columns:
            zone_counts = data["Adresse"].value_counts().reset_index()
            zone_counts.columns = ["Zone", "Nombre d'Annonces"]
            fig2 = px.bar(zone_counts, x="Zone", y="Nombre d'Annonces", title="Nombre d'Annonces par Zone")
            st.plotly_chart(fig2, use_container_width=True)

            prix_moyen_par_zone = data.groupby("Adresse")["Prix"].mean().reset_index()
            prix_moyen_par_zone.columns = ["Zone", "Prix Moyen"]

            # Graphique des prix moyens par zone
            fig_prix_moyen = px.bar(prix_moyen_par_zone, 
                                     x="Zone", y="Prix Moyen", 
                                     title="Distribution du Prix Moyen par Zone", 
                                     labels={"Zone": "Zones", "Prix Moyen": "Prix Moyen (FCFA)"})
            st.plotly_chart(fig_prix_moyen, use_container_width=True)

        # ğŸŒŸ Graphique 3 : RÃ©partition des Ã©tats des climatiseurs
        if "Etat_Clim" in data.columns:
            fig3 = px.pie(data, names="Etat_Clim", title="RÃ©partition des Ã‰tats des Climatiseurs")
            st.plotly_chart(fig3, use_container_width=True)

        # ğŸ’¾ TÃ©lÃ©chargement des donnÃ©es
        csv_data = data.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ’¾ TÃ©lÃ©charger les donnÃ©es en CSV", csv_data, "data_dashboard.csv", "text/csv")
    else:
        st.info("ğŸ“‰ Aucune donnÃ©e disponible pour la visualisation.")

# --- Ã‰valuation ---
if menu == "ğŸ“ Ã‰valuation":
    st.header("Formulaire d'Ã‰valuation ğŸ“")
    st.image(evaluation_img, caption="Donnez-nous votre avis !", use_column_width=True)

    note = st.slider("Quelle note donnez-vous Ã  l'application ?", min_value=1, max_value=5, value=3)
    commentaire = st.text_area("Commentaires supplÃ©mentaires")

    if st.button("âœ… Soumettre l'Ã©valuation"):
        with st.spinner("Enregistrement de votre Ã©valuation..."):
            time.sleep(2)
        st.success("Merci pour votre Ã©valuation ! ğŸ‰")
        st.write(f"Note attribuÃ©e : {note} â­")
        st.write(f"Commentaire : {commentaire}")

# Charger des DonnÃ©es ScrapÃ©es
elif menu == "ğŸ“¥ Charger des DonnÃ©es ScrapÃ©es":
    st.header("ğŸ“¥ Charger des DonnÃ©es ScrapÃ©es")

    uploaded_file = st.file_uploader("TÃ©lÃ©chargez votre fichier CSV :", type=["csv"])
    
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.success("âœ… Fichier chargÃ© avec succÃ¨s !")
        st.write("AperÃ§u des donnÃ©es :")
        st.dataframe(df)
        
        # Option d'analyse rapide
        if st.checkbox("Afficher une analyse rapide"):
            st.write(df.describe())

        # Graphiques optionnels
        if st.checkbox("Afficher un graphique de distribution des prix"):
            fig = px.histogram(df, x="Prix", title="Distribution des Prix")
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ğŸ“‚ Veuillez charger un fichier CSV.")





st.markdown(
    """
    <div style='text-align: center; margin-top: 100px; font-size: 14px; color: gray;'>
        @ DÃ©veloppÃ© par <strong>Ousmane SOW</strong> - 2025
    </div>
    """,
    unsafe_allow_html=True,
)